{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import faiss\n",
    "import langchain\n",
    "from langchain import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load openAI api key\n",
    "load_dotenv()\n",
    "# Access the environment variable\n",
    "open_api_key = os.getenv('OPEN_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = open_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise LLM with required params\n",
    "llm = OpenAI(temperature=0.9, max_tokens=500) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "])\n",
    "data = loaders.load() \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# As data is of type documents we can directly use split_documents over split_text in order to get the chunks.\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings for these chunks and save them to FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embeddings of the chunks using openAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Pass the documents and embeddings inorder to create FAISS vector index\n",
    "vectorindex_openai = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x000001E33DFE5920> >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming vectorindex_openai is an instance of FAISS\n",
    "index = vectorindex_openai.index\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "file_path = \"vector_index.faiss\"\n",
    "docstore_path = \"vector_index_docstore.pkl\"\n",
    "index_to_docstore_id_path = \"vector_index_index_to_docstore_id.pkl\"\n",
    "\n",
    "if not (os.path.exists(file_path) and os.path.exists(docstore_path) and os.path.exists(index_to_docstore_id_path)):\n",
    "    # Create the embeddings of the chunks using OpenAIEmbeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # Pass the documents and embeddings in order to create FAISS vector index\n",
    "    # vectorindex_openai = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    # Save the FAISS index to a file\n",
    "    index = vectorindex_openai.index\n",
    "    faiss.write_index(index, file_path)\n",
    "\n",
    "    # Save the docstore and index_to_docstore_id separately\n",
    "    with open(docstore_path, \"wb\") as f:\n",
    "        pickle.dump(vectorindex_openai.docstore, f)\n",
    "\n",
    "    with open(index_to_docstore_id_path, \"wb\") as f:\n",
    "        pickle.dump(vectorindex_openai.index_to_docstore_id, f)\n",
    "\n",
    "    # Save the embedding function separately if it is picklable\n",
    "    # If not, you may need to recreate it during loading\n",
    "    embedding_function = vectorindex_openai.embedding_function\n",
    "else:\n",
    "    print(\"FAISS index already exists. Skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "file_path = \"vector_index.faiss\"\n",
    "docstore_path = \"vector_index_docstore.pkl\"\n",
    "index_to_docstore_id_path = \"vector_index_index_to_docstore_id.pkl\"\n",
    "\n",
    "if os.path.exists(file_path) and os.path.exists(docstore_path) and os.path.exists(index_to_docstore_id_path):\n",
    "    # Load the FAISS index from a file\n",
    "    index = faiss.read_index(file_path)\n",
    "\n",
    "    # Load the docstore and index_to_docstore_id\n",
    "    with open(docstore_path, \"rb\") as f:\n",
    "        docstore = pickle.load(f)\n",
    "\n",
    "    with open(index_to_docstore_id_path, \"rb\") as f:\n",
    "        index_to_docstore_id = pickle.load(f)\n",
    "\n",
    "    # Recreate the embedding function if necessary\n",
    "    embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "    # Recreate the FAISS object with the loaded index and additional data\n",
    "    vectorIndex = FAISS(\n",
    "        index=index,\n",
    "        embedding_function=embedding_function,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id\n",
    "    )\n",
    "else:\n",
    "    print(\"FAISS index files do not exist. Please create the index first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve similar embeddings for a given question and call LLM to retrieve final answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
